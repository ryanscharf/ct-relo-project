---
title: "CT-Relo-Project"
author: "frank-corrigan"
date: "1/3/2022"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# install packages
# if(!require("osmdata")) install.packages("osmdata")
# if(!require("tidyverse")) install.packages("tidyverse")
# if(!require("sf")) install.packages("sf")
# if(!require("ggmap")) install.packages("ggmap")
# if(!require("rgdal")) install.packages("rgdal")
# if(!require("geosphere")) install.packages("geosphere")
# if(!require("ggplot2")) install.packages("ggplot2")

# load packages
library(tidyverse)
library(osmdata)
library(sf)
# library(ggmap)
# library(rgdal)
# library(geosphere)
library(tmap)
library(tigris)
#library(furrr)
library(tidycensus)
#library(parallel)
library(rvest)
library(httr)
library(polite)
library(janitor)
library(units)
```

## Background

Document to reproduce metrics and visualizations used in this article: http://www.frank-corrigan.com/2022/01/03/where-should-we-live/

First order is to load disperate data files (including shape files for maps)...

```{r load_data, message=FALSE, warning=FALSE}
acs_yr <- 2021
acs_survey <- 'acs1'

median_home_value_co <-
  get_acs(
    geography = 'county',
    variables = c('B25077_001'),
    year = acs_yr,
    survey = acs_survey
  )

#filter states to contiguous US
states <- tigris::states(cb = T ) %>% 
  filter(!STATEFP %in% c('02', '15', '60', '66', '69', '72', '78'))

counties <- tigris::counties(state = states$STATEFP, cb = T)


```

## Getting Trails Data

You can also embed plots, for example:

```{r get_trails_data}

##  NOTE: commenting out this section -
##  no need to do the loop again unless you want to update the data or search for different tags (like beaches)

## subset towns and locatins to pull osm data for...
# data_for_osm <- counties %>% select(STATEFP, GEOID) # %>% st_centroid()

## instead of writing the long form several times below
 # towns <- data_for_osm@data$NAME00
 # lats <- data_for_osm$INTPTLAT00
 # lons <- data_for_osm$INTPTLON00

## create an empty dataframe
 # trail_df <- data.frame(county=NULL, path_node_count=NULL)

## loop through towns and use osm API to get nodes tagged as footway or cycleway
 # for (i in 1:length(towns)) {

  # # set coords & location: from each town center, search ~10 mile radius..
  # coords <- matrix(
  #   c(lons[i] - 0., 
  #     lons[i] + 0.16, 
  #     lats[i] - 0.16, 
  #     lats[i] + 0.16), 
  #   byrow = TRUE, 
  #   nrow = 2, 
  #   ncol = 2, 
  #   dimnames = list(c('x','y'),c('min','max'))
  #   )
  # location <- coords %>% opq()
    
  # # get trail node data
  # temp_data <- location %>%
  #   add_osm_feature(key = "highway",
  #                   value = c("footway", "cycleway")) %>%
  #   osmdata_sf()


path_count_fn <- function(x) {
  df <- x %>%
    #pluck(1) %>%
    add_osm_feature(key = "highway",
                    value = c("footway", "cycleway")) %>%
    osmdata_sf()
  
  temp_node_count <- nrow(df$osm_points)
  return(temp_node_count)
}

possib_path <- possibly(.f = path_count_fn)

 # working loop to get the osm data
# nodes_df <- data.frame(GEOID = NULL, nodes = NULL)
# 
# for( i in 1:nrow(counties)){
#    cat(paste0(i,'\n'))
#   
#   go <- st_drop_geometry(counties[i, 'GEOID'])
#   x <- opq(bbox = st_bbox(counties[i, ]))
#   
#   df <- possib_path(x)
#     
#   res = data.frame(GEOID = go, nodes = df)
#   
#   nodes_df <- bind_rows(nodes_df, res)
#   
# }


# this map technique is definitely not working for me.
# I think the osm endpoint doesn't like getting a ton of 
# simultaneous requests from the same ip
# 
# location <- purrr::map(counties$geometry, ~ opq(bbox = st_bbox(.x)))
# 
#  ncores <- parallel::detectCores() - 2
#   plan(multisession, workers = ncores)
#   
#   osm_results <- furrr::future_map(location, 
#                                    .f = ~definitely_get_data(path_count_fn(.x)), .progress = T) %>%
#     bind_rows()
#   
#   osm_results_j <- counties %>% 
#     st_drop_geometry() %>% 
#     select(GEOID) %>%
#     bind_cols(osm_results)

  # nodes_df %>% write_csv('county_node_count.csv')
  # beepr::beep(2)
   
  nodes_df <- read_csv('county_node_count.csv')
  
  trail_df <- counties %>% left_join(nodes_df, by = 'GEOID')

 # print(head(trail_df))

# trail_df <- read.csv("osm_path_node_count.csv")

```

## Getting Distance to Airport Data

```{r airports}

# airport_file <- "https://www.partow.net/downloads/GlobalAirportDatabase.zip"
# zp_f <- tempfile(fileext = '.zip')
# download.file(airport_file, zp_f, mode = 'wb')
# 
# airports <- read_delim(
#   zp_f,
#   delim = ":",
#   escape_double = FALSE,
#   col_names = FALSE,
#   col_types = cols(
#     X6 = col_skip(),
#     X7 = col_skip(),
#     X8 = col_skip(),
#     X9 = col_skip(),
#     X10 = col_skip(),
#     X11 = col_skip(),
#     X12 = col_skip(),
#     X13 = col_skip(),
#     X14 = col_integer()
#   ),
#   trim_ws = TRUE
# )

# names(airports) <- c(
#   'ICAO',
#   'IATA',
#   'name',
#   'city',
#   'country',
#   'altitude',
#   'latitude',
#   'longitude'
# )

airports <- read_csv("https://raw.githubusercontent.com/lxndrblz/Airports/main/airports.csv", 
    col_types = cols(time_zone_id = col_skip(), 
        url = col_skip())) %>% 
  rename(geometry = location) %>% 
  st_as_sf(wkt = 'geometry', crs = 4269)
  

airports <- airports %>% 
  filter(country_id == 'US',
         # latitude != 0, 
         # longitude != 0,
         !str_detect(name, 'AFB|AAF'),
         !is.na(icao))

# there's way too mainy nonpassenger/primary airports in the first list
# we will grab the wikipedia list of airpots, which looks reasonable 
# and use that to filter the geocoded list
# 
# https://ivelasq.rbind.io/blog/politely-scraping/

wiki_url <- 'https://en.wikipedia.org/wiki/List_of_airports_in_the_United_States'
url_bow <- polite::bow(wiki_url)

wiki_html <- polite::scrape(url_bow) %>%
  html_nodes('table.wikitable') %>%
  html_table(fill = T)

wiki_tbl <- wiki_html[[1]] %>% 
  janitor::clean_names() %>% 
  filter(faa != '')


airports <- airports %>% 
  filter(icao %in% wiki_tbl$icao)


distances <- st_distance(counties, airports)

#find minimum distance to airport 
min_dist <- do.call(pmin, as.data.frame(distances))

trail_df <- trail_df %>% 
  mutate(
    min_dist_airport = set_units(min_dist, 'miles')
    )

# # lat/lon major airports around CT
# lga <- c(-73.8740, 40.7769)
# jfk <- c(-73.7781, 40.6413)
# bdl <- c(-72.6860, 41.9389)
# pvd <- c(-71.4270, 41.7235)
# bos <- c(-71.0096, 42.3656)
# 
# # lat/lon needs to be numeric
# my_spdf@data$INTPTLAT00 <- as.numeric(my_spdf@data$INTPTLAT00)
# my_spdf@data$INTPTLON00 <- as.numeric(my_spdf@data$INTPTLON00)

# # for each town (i.e. row of data), use the lowest distance to any airport
# my_spdf@data$dist_lga <- distHaversine(as.matrix(my_spdf@data[,c("INTPTLON00", "INTPTLAT00")]), lga) * 0.000621371
# my_spdf@data$dist_jfk <- distHaversine(as.matrix(my_spdf@data[,c("INTPTLON00", "INTPTLAT00")]), jfk) * 0.000621371
# my_spdf@data$dist_bdl <- distHaversine(as.matrix(my_spdf@data[,c("INTPTLON00", "INTPTLAT00")]), bdl) * 0.000621371
# my_spdf@data$dist_pvd <- distHaversine(as.matrix(my_spdf@data[,c("INTPTLON00", "INTPTLAT00")]), pvd) * 0.000621371
# my_spdf@data$dist_bos <- distHaversine(as.matrix(my_spdf@data[,c("INTPTLON00", "INTPTLAT00")]), bos) * 0.000621371
# my_spdf@data$dist_to_airport <- apply(my_spdf@data[,c("dist_lga", "dist_jfk", "dist_bdl", "dist_pvd", "dist_bos")], 1, FUN = min)

```


```{r hunt down disc golf courses} 
centroid_latlon <- function(x){
  df <- x %>% st_centroid() %>% st_coordinates()
  c(df[2], df[1])
}

pdga_url <- "https://www.pdga.com/course-directory/advanced?title=&field_course_location_country=US&field_course_location_locality=&field_course_location_administrative_area=All&field_course_location_postal_code=&field_course_type_value=All&rating_value=All&field_course_holes_value=All&field_course_total_length_value=All&field_course_target_type_value=All&field_course_tee_type_value=All&field_location_type_value=All&field_course_camping_value=All&field_course_facilities_value=All&field_course_fees_value=All&field_course_handicap_value=All&field_course_private_value=All&field_course_signage_value=All&field_cart_friendly_value=All&page={page}"
pdga_base <- 'https://www.pdga.com'

pdga_pages <- 151
page <- seq(0, pdga_pages, 1) 

# test_page <- "https://www.pdga.com/course-directory/advanced?title=&field_course_location_country=US&field_course_location_locality=&field_course_location_administrative_area=All&field_course_location_postal_code=&field_course_type_value=All&rating_value=All&field_course_holes_value=All&field_course_total_length_value=All&field_course_target_type_value=All&field_course_tee_type_value=All&field_location_type_value=All&field_course_camping_value=All&field_course_facilities_value=All&field_course_fees_value=All&field_course_handicap_value=All&field_course_private_value=All&field_course_signage_value=All&field_cart_friendly_value=All&page=1"

get_courses <- function(p_url, pdga_base = 'https://www.pdga.com'){
  
  url_bow <- polite::bow(p_url)
  url_scrap <- url_bow %>% 
    polite::scrape()
  
  nams <- url_scrap %>%
    html_nodes('.views-field-title') %>% 
    html_text2()
  
  nams <- nams[2:51]
  
  links <- url_scrap %>% html_nodes('a') %>% html_attr('href')
  links <- links[121:170]
  links_p <- paste0(pdga_base, links)

data.frame(course = nams, 
           link = links_p)
}

get_coords <- function(link){
  
  url_bow <- polite::bow(link)
  
  c <- url_bow %>% polite::scrape() %>% html_nodes('a') %>% html_attr('href')
  c <- c[str_detect(c, 'maps') & !is.na(c)][2]
  c <- str_extract(c, '(?<=q=).*') %>% str_split(',')
  c_lat <- c[[1]][1] %>% as.numeric()
  c_lon <- c[[1]][2] %>% as.numeric()
  
  data.frame(link = l1,
             latitude = c_lat,
             longitude = c_lon)
}

#takes 25 minutes
courses <- map_df(glue(pdga_url), get_courses)
courses %>% write_csv('courses.csv')

#will take 5 days
course_geo <- map_df(courses$link, get_coords, .progress = T)
saveRDS(course_geo, 'course_geo.rds')

coureses %>% left_join(course_geo) %>% write_csv('courses_geo.csv')
```





## Distributions

```{r distributions}

# first, bring the data together... 
my_spdf@data <- left_join(my_spdf@data, school_data, by="NAME00") %>%
  left_join(trail_df, by=c("NAME00"="town"))

# these are the columns we want to peek at
plot_dist_data <- my_spdf@data %>% select(adj_home_price, age, population_growth,
                                          population_density, school_outcomes, path_node_count,
                                          dist_to_airport)

library(reshape2)
plot_dist_data_melt <- melt(plot_dist_data)

# finally, plot histograms
ggplot(plot_dist_data_melt, aes(x=value)) + geom_histogram() + facet_wrap(~variable, scales="free")

```

## Setting Up for Maps!

``` {r map-setup}

# create lists for colors and range names
col_list <- c("#7b3294", "#c2a5cf", "#f7f7f7", "#a6dba0", "#008837")
labels_list <- c("Lowest", "Low", "Medium", "High", "Highest")

# add id field (allows for join to fortified df when creating maps)
my_spdf@data$id <- 0:(dim(my_spdf@data)[1]-1) 

```

## House Prices

``` {r house-prices,  fig.width = 10, fig.asp = .52}

# create dataset for map visualization
World2 <- fortify(my_spdf)
World2_join = plyr::join(x = World2, y = my_spdf@data, by="id") # join by id
World2_join <- World2_join %>% filter(NAME00 != "County subdivisions not defined")
World2_join$cost_bucket <- cut(World2_join$adj_home_price, 6)

ggplot() + 
  geom_polygon(data = World2_join, aes(x = long, y = lat, group = group, fill = cost_bucket), # fill by OCCURENCE
               colour = "black", size = 0.5) +
  scale_color_manual(values = col_list, labels = labels_list) +
  scale_fill_manual(values = col_list, labels = labels_list) +
  geom_text(data=my_spdf@data %>% filter(NAME00 != "County subdivisions not defined"), aes(INTPTLON00, INTPTLAT00, label = NAME00), size=2.5) +
  labs(fill="House Price Ranges") +
  annotate("label", x = -72.25, y = 41, size = 7, label = expression(atop("CT Home Prices by Town", "(~2019 adjusted for mill rates)"))) +
  annotate("text", x = -72.70, y = 41.18, label = "Long Island Sound") +
  theme(panel.background = element_blank(),
      axis.title=element_blank(),
      axis.text=element_blank(),
      axis.ticks=element_blank())

```

## Trail Systems

``` {r trail-systems,  fig.width = 10, fig.asp = .52}

# create dataset for map visualization
World2 <- fortify(my_spdf)
World2_join = plyr::join(x = World2, y = my_spdf@data, by="id") # join by id
World2_join <- World2_join %>% filter(NAME00 != "County subdivisions not defined")
World2_join$cost_bucket <- cut(World2_join$path_node_count, 5)

ggplot() + 
  geom_polygon(data = World2_join, aes(x = long, y = lat, group = group, fill = cost_bucket), # fill by OCCURENCE
               colour = "black", size = 0.5) +
  scale_color_manual(values = col_list, labels = labels_list) +
  scale_fill_manual(values = col_list, labels = labels_list) +
  geom_text(data=my_spdf@data %>% filter(NAME00 != "County subdivisions not defined"), aes(INTPTLON00, INTPTLAT00, label = NAME00), size=2.5) +
  labs(fill="Trail Count Ranges") +
  annotate("label", x = -72.25, y = 41, size = 7, label = expression(atop("CT Trail Node Count by Town", "(~2021 from OSM data)"))) +
  annotate("text", x = -72.70, y = 41.18, label = "Long Island Sound") +
  theme(panel.background = element_blank(),
      axis.title=element_blank(),
      axis.text=element_blank(),
      axis.ticks=element_blank())

```

``` {r trail-systems-vis}

# get centerpoints for town of interest
guilford <- c(-72.70609, 41.33903)
farmington <- c(-72.84305, 41.73042)
the_spot <- farmington

# define "radius" from which to count trail system nodes
coords <- matrix(c(the_spot[1] - 0.16, the_spot[1] + 0.16, the_spot[2] - 0.16, the_spot[2] + 0.16), byrow = TRUE, nrow = 2, ncol = 2, dimnames = list(c('x','y'),c('min','max')))
location <- coords %>% opq()

# get data from osm
data <- location %>%
  add_osm_feature(key = "highway", 
                  value = c("footway", "cycleway")) %>%
  osmdata_sf()

# register_google(key = "Aanrq39hrf7rabgwegs-adsfawe") # note this is random key (i.e. not real - get a Google Maps API credential and Enable Static Maps from Google Console)
# has_google_key()

mad_map <- get_map(location = c(lon = the_spot[1], lat = the_spot[2]), zoom = 12)

# final map
ggmap(mad_map)+
  geom_sf(data = data$osm_points,
          inherit.aes = FALSE,
          colour = "#238443",
          fill = "#004529",
          alpha = .1,
          size = 4,
          shape = 21) +
  labs(x = "", y = "", title = "Farmington") 

```



## Proximity to Airport

``` {r distance-to-airport,  fig.width = 10, fig.asp = .52}

# create dataset for map visualization
World2 <- fortify(my_spdf)
World2_join = plyr::join(x = World2, y = my_spdf@data, by="id") # join by id
World2_join <- World2_join %>% filter(NAME00 != "County subdivisions not defined")
World2_join$cost_bucket <- cut(World2_join$dist_to_airport, 5)

ggplot() + 
  geom_polygon(data = World2_join, aes(x = long, y = lat, group = group, fill = cost_bucket), # fill by OCCURENCE
               colour = "black", size = 0.5) +
  scale_color_manual(values = col_list, labels = labels_list) +
  scale_fill_manual(values = col_list, labels = labels_list) +
  geom_text(data=my_spdf@data %>% filter(NAME00 != "County subdivisions not defined"), aes(INTPTLON00, INTPTLAT00, label = NAME00), size=2.5) +
  labs(fill="Miles to Airport Ranges") +
  annotate("label", x = -72.25, y = 41, size = 7, label = expression("CT Distance to Airport by Town", "(~2021 from CT Shape File Data)")) +
  annotate("text", x = -72.70, y = 41.18, label = "Long Island Sound") +
  theme(panel.background = element_blank(),
        axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank())

```
## Putting it All Together

``` {r overall-score, fig.width = 10, fig.asp = .52}

my_spdf@data$score <- scale(my_spdf@data$school_outcomes) * 0.35 +
  scale(my_spdf@data$path_node_count) * 0.35 -
  scale(my_spdf@data$adj_home_price) * 0.2 -
  scale(my_spdf@data$dist_to_airport) * 0.1

# create dataset for map visualization
World2 <- fortify(my_spdf)
World2_join = plyr::join(x = World2, y = my_spdf@data, by="id") # join by id
World2_join <- World2_join %>% filter(NAME00 != "County subdivisions not defined")
World2_join$cost_bucket <- cut(World2_join$score, 5)

ggplot() + 
  geom_polygon(data = World2_join, aes(x = long, y = lat, group = group, fill = cost_bucket), # fill by OCCURENCE
               colour = "black", size = 0.5) +
  scale_color_manual(values = col_list, labels = labels_list) +
  scale_fill_manual(values = col_list, labels = labels_list) +
  geom_text(data=my_spdf@data %>% filter(NAME00 != "County subdivisions not defined"), aes(INTPTLON00, INTPTLAT00, label = NAME00), size=2.5) +
  labs(fill="Overall Score Ranges") +
  annotate("label", x = -72.25, y = 41, size = 7, label = expression("CT Relo Score by Town")) +
  annotate("text", x = -72.70, y = 41.18, label = "Long Island Sound") +
  theme(panel.background = element_blank(),
        axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank())

```